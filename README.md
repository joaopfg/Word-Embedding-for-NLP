# Word Embedding for NLP

Generate word embedding using UIE (word as graph node, sentence as graph node), SDP (sentence as graph node), and test using a NN for sentiment classification.

## Contents
- folder  `universal isotropic embedding`: codes to generate word embedding using UIE 
	- folder `GDM5_test800`: train and test data with word set = 800, 5-gram
		- `X_uie.npy`: generated by UIE, word as node 
		- `X_uiesb.npy`: generated by UIE, sentence as node 
		- `X_dg4wv.npy`: generated by solving SDP
		- `word_list`: corresponding word for each test instance 
		- 'Y.npy': labels for each word vector 
	- folder `GDM3_test1000`: train and test data with word set = 800, 3-gram
		- Same as above
	- `gen_GDM.py`: generate the GDM after applying UIE, save to .npy file
	- `retrive_X_Y_from_dat.ipynb`: use the .npy file to generate train and test X,Y
- `word2node.ipynb`: contains the model 
- ``MP solution for DGP.ipynb': word embedding using SDP
